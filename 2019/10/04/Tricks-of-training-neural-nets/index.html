<!DOCTYPE html>
<html style="display: none;" lang="en">
    <head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.6 -->
    <script>
        window.materialVersion = "1.5.6"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1',
            '1.5.0',
            '1.5.2',
            '1.5.5'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">





    <link rel="dns-prefetch" href="https://EtoDemerzel.disqus.com">



    <link rel="dns-prefetch" href="https://www.google-analytics.com">



    <link rel="dns-prefetch" href="https://fonts.proxy.ustclug.org">





    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!-- Title -->
    
    <title>
        
            Tricks of training neural nets | 
        
        My Trantor
    </title>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="https://s1.ax1x.com/2018/09/03/PznrKH.png">
    <link rel="icon" href="https://s1.ax1x.com/2018/09/03/PznrKH.png">

    <meta name="format-detection" content="telephone=no">
    <meta name="description" itemprop="description" content="How to train neural networks has been a huge challenge to researchers since the very first day of deep learning.">
    <meta name="keywords" content="Deep Learning Data Mining,Deep Learning,tutorial">
    <meta name="theme-color" content="#3B4247">

    <!-- Disable Fucking Bloody Baidu Tranformation -->
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta http-equiv="Cache-Control" content="no-siteapp">

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.en.js"></script>
        
    <![endif]-->

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(a){try{localStorage.removeItem(a)}catch(b){}};lsloader.setLS=function(a,c){try{localStorage.setItem(a,c)}catch(b){}};lsloader.getLS=function(a){var c="";try{c=localStorage.getItem(a)}catch(b){c=""}return c};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var b=[];for(var a=0;a<localStorage.length;a++){b.push(localStorage.key(a))}b.forEach(function(e){var f=lsloader.getLS(e);if(window.oldVersion){var d=window.oldVersion.reduce(function(g,h){return g||f.indexOf("/*"+h+"*/")!==-1},false);if(d){lsloader.removeLS(e)}}})}catch(c){}};lsloader.clean();lsloader.load=function(f,a,b,d){if(typeof b==="boolean"){d=b;b=undefined}d=d||false;b=b||function(){};var e;e=this.getLS(f);if(e&&e.indexOf(versionString)===-1){this.removeLS(f);this.requestResource(f,a,b,d);return}if(e){var c=e.split(versionString)[0];if(c!=a){console.log("reload:"+a);this.removeLS(f);this.requestResource(f,a,b,d);return}e=e.split(versionString)[1];if(d){this.jsRunSequence.push({name:f,code:e});this.runjs(a,f,e)}else{document.getElementById(f).appendChild(document.createTextNode(e));b()}}else{this.requestResource(f,a,b,d)}};lsloader.requestResource=function(b,e,a,c){var d=this;if(c){this.iojs(e,b,function(h,f,g){d.setLS(f,h+versionString+g);d.runjs(h,f,g)})}else{this.iocss(e,b,function(f){document.getElementById(b).appendChild(document.createTextNode(f));d.setLS(b,e+versionString+f)},a)}};lsloader.iojs=function(d,b,g){var a=this;a.jsRunSequence.push({name:b,code:""});try{var f=new XMLHttpRequest();f.open("get",d,true);f.onreadystatechange=function(){if(f.readyState==4){if((f.status>=200&&f.status<300)||f.status==304){if(f.response!=""){g(d,b,f.response);return}}a.jsfallback(d,b)}};f.send(null)}catch(c){a.jsfallback(d,b)}};lsloader.iocss=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.iofonts=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.runjs=function(f,c,e){if(!!c&&!!e){for(var b in this.jsRunSequence){if(this.jsRunSequence[b].name==c){this.jsRunSequence[b].code=e}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var a=document.createElement("script");a.appendChild(document.createTextNode(this.jsRunSequence[0].code));a.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(a);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else{if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var d=this;var a=document.createElement("script");a.src=this.jsRunSequence[0].path;a.type="text/javascript";this.jsRunSequence[0].status="loading";a.onload=function(){d.jsRunSequence.shift();if(d.jsRunSequence.length>0){d.runjs()}};document.body.appendChild(a)}}};lsloader.tagLoad=function(b,a){this.jsRunSequence.push({name:a,code:"",path:b,status:"failed"});this.runjs()};lsloader.jsfallback=function(c,b){if(!!this.jsnamemap[b]){return}else{this.jsnamemap[b]=b}for(var a in this.jsRunSequence){if(this.jsRunSequence[a].name==b){this.jsRunSequence[a].code="";this.jsRunSequence[a].status="failed";this.jsRunSequence[a].path=c}}this.runjs()};lsloader.cssfallback=function(e,c,b){if(!!this.cssnamemap[c]){return}else{this.cssnamemap[c]=1}var d=document.createElement("link");d.type="text/css";d.href=e;d.rel="stylesheet";d.onload=d.onerror=b;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(d,a)};lsloader.runInlineScript=function(c,b){var a=document.getElementById(b).innerText;this.jsRunSequence.push({name:c,code:a});this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?NKhlKQkXw/c66TR5p4wO+w==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #378bc8;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #3B4247 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #3B4247 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #3B4247 !important;
  }

  .toTop {
    background: #c1c4c6 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #c1c4c6;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #c1c4c6;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #c1c4c6;
  }

  .post-toc a:hover {
    color: #378bc8;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #F5F5F5;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.proxy.ustclug.org/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icons -->


    <style id="material_icons"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_icons","/css/material-icons.css?pqhB/Rd/ab0H2+kZp0RDmw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","https://cdn.bootcss.com/jquery/2.2.1/jquery.js", true)</script>
    

    <!-- WebAPP Icons -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="application-name" content="My Trantor">
    <meta name="msapplication-starturl" content="https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/">
    <meta name="msapplication-navbutton-color" content="#3B4247">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="My Trantor">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon" href="https://s1.ax1x.com/2018/09/03/PznrKH.png">

    <!-- Site Verification -->
    <meta name="google-site-verification" content="Qdr-ePYrpfokzie4PUuT0TfVUd_cjS39wQt624NouvM">
    <meta name="baidu-site-verification" content="qW1rbkxBrE">

    <!-- RSS -->
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Tricks of training neural nets | My Trantor">
    <meta property="og:image" content="https://s1.ax1x.com/2018/09/03/PznrKH.png">
    <meta property="og:description" content="How to train neural networks has been a huge challenge to researchers since the very first day of deep learning.">
    <meta property="og:article:tag" content="Deep Learning"> <meta property="og:article:tag" content="tutorial"> 

    
        <meta property="article:published_time" content="Fri Oct 04 2019 22:22:18 GMT+0800">
        <meta property="article:modified_time" content="Sun Oct 06 2019 15:31:12 GMT+0800">
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:card" content="summary_large_image">

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html">
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html",
    "headline": "Tricks of training neural nets",
    "datePublished": "Fri Oct 04 2019 22:22:18 GMT+0800",
    "dateModified": "Sun Oct 06 2019 15:31:12 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "Weiran Huang",
        "image": {
            "@type": "ImageObject",
            "url": "https://s1.ax1x.com/2018/09/03/PznIMQ.png"
        },
        "description": "My life of code, math and literature"
    },
    "publisher": {
        "@type": "Organization",
        "name": "My Trantor",
        "logo": {
            "@type":"ImageObject",
            "url": "https://s1.ax1x.com/2018/09/03/PznrKH.png"
        }
    },
    "keywords": ",Deep Learning,tutorialDeep Learning Data Mining",
    "description": "How to train neural networks has been a huge challenge to researchers since the very first day of deep learning.",
}
</script>


    

    <!-- Analytics -->
    
        <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
    ga('create', 'UA-111871163-1', 'auto');ga('send', 'pageview');
</script>
    
    
    

    <!-- Custom Head -->
    

<link rel="alternate" href="/atom.xml" title="My Trantor" type="application/atom+xml">
<link rel="stylesheet" href="/css/prism-ghcolors.css" type="text/css"></head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span id="MD-burger-id" class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Basics"><span class="post-toc-number">1.</span> <span class="post-toc-text">Basics</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Tools-for-optimization"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">Tools for optimization</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Tips-for-tuning-hyperparamters"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">Tips for tuning hyperparamters</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Advanced-Topics"><span class="post-toc-number">2.</span> <span class="post-toc-text">Advanced Topics</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Activation-functions"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">Activation functions</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Optimizers"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">Optimizers</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Batch-normalization"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">Batch normalization</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Gradient-clipping"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">Gradient clipping</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Others"><span class="post-toc-number">3.</span> <span class="post-toc-text">Others</span></a></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        <!-- Custom Thumbnail -->
        <div class="post_thumbnail-custom mdl-card__media mdl-color-text--grey-50" style="background-image:url(https://s2.ax1x.com/2019/10/05/us9L34.png)">
    
            <p class="article-headline-p">
                Tricks of training neural nets
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="https://s1.ax1x.com/2018/09/03/PznIMQ.png" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Weiran Huang</strong>
        <span>Oct 04, 2019</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/Deep-Learning/">Deep Learning</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/tutorial/">tutorial</a>
    </ul>
    

    <!-- Share -->
    
        <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=Tricks of training neural nets&url=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html&pic=https://huangweiran.clubhttps://s1.ax1x.com/2018/09/03/PznrKH.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                Share to Weibo
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=Tricks of training neural nets&url=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html&via=Weiran Huang" target="_blank">
            <li class="mdl-menu__item">
                Share to Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html" target="_blank">
            <li class="mdl-menu__item">
                Share to Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html" target="_blank">
            <li class="mdl-menu__item">
                Share to Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    
        <a class="post_share-link" href="https://www.linkedin.com/shareArticle?mini=true&url=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html&title=Tricks of training neural nets" target="_blank">
            <li class="mdl-menu__item">
                Share to LinkedIn
            </li>
        </a>
    

    <!-- Share QQ -->
    
        <a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=My Trantor&title=Tricks of training neural nets&summary=Machine Learning Python Deep Data Mining Computer Science&pics=https://huangweiran.clubhttps://s1.ax1x.com/2018/09/03/PznrKH.png&url=https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/index.html" target="_blank">
            <li class="mdl-menu__item">
                Share to QQ
            </li>
        </a>
    

    <!-- Share Telegram -->
    
</ul>

    
</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <p>How to train neural networks has been a huge challenge to researchers since the very first day of deep learning. <a id="more"></a>Unlike most classic machine learning algorithms, neural networks, especially deep ones, require more data and more parameters to tune, which make them more versatile, powerful and scalable to express the distribution of  real-world data, but also create huge difficulty for training.</p>
<p>Neural networks, or artificial neural networks(ANNs), are said to be inspired by the biological neurons. It was first introduced in 1943 (surprisingly early, uh?), but progress was slow.  The training technique remained challenging until the invention of back propagation in 1986. In short, it is still gradient descent as in many classic machine learning algorithms, but back propagation combines it with chain rule. Back propagation is an algorithm that is still widely used today, and it is with no doubt one of the biggest breakthroughs in the history of deep learning. With this algorithm, for the first time people began to believe that it is feasible to train a neural network. However, due to the complex hypothesis space, training a neural net still requires much experiences and some fancy tricks, and this is why I am writing this blog post today.</p>
<p>Most part of this article comes from the wonderful book, <em>Hands on Machine Learning with Scikit-learn and Tensorflow, 2nd edition</em>, many thanks to the authors.</p>
<h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><h3 id="Tools-for-optimization"><a href="#Tools-for-optimization" class="headerlink" title="Tools for optimization"></a>Tools for optimization</h3><p>Grid search and randomized search have been universal solutions to fine-tuning the hyperparamters for most machine learning algorithms, and luckily, they can be applied to deep learning too. If you are using Keras or tf.Keras, you are super lucky because you can wrap up your Keras models with <code>keras.wrappers.scikit_learn</code>, so that you can use <code>GridSearchCV</code> and <code>RandomizedSearchCV</code> in scikit-learn. </p>
<p>You can also use some Python libraries to optimize hyperparameters, for example, Hyperopt, hyperas, Scikit-Optimize. Also, companies like Google are offering hyperparameter optimization services now, such as hyperparameter tuning services provided by Google Cloud ML Engine. Moreover, nowadays, AutoML has been a heated topic, and there have been such kind of services available: maybe the handmade training era will end soon?</p>
<p>It is possible, and very promising. But we have to admit there is still a long way to go, and that is why you still need to learn about training tricks today.</p>
<h3 id="Tips-for-tuning-hyperparamters"><a href="#Tips-for-tuning-hyperparamters" class="headerlink" title="Tips for tuning hyperparamters"></a>Tips for tuning hyperparamters</h3><p>We all know deeper networks can model more complex functions, but they are harder to train. So when we are designing our models, it can be tough to decide <strong>the number of hidden layers</strong>. For this, the best (and maybe easiest) practice could be gradually ramp up the numbers until starting to overfitting.</p>
<p>Another hyperparameter you have to consider is <strong>the number of neurons per layer</strong>. People found that using the same number of neurons in all hidden layers performs good enough. It is good because in this way we only have one hyperparameter to tune instead of one per layer. Just like for the number of layers, we can try increasing the number of neurons gradually until the network starts overfitting. But experience tells us it is hard to implement. A simpler approach is to pick a model with more layers and neurons than we actually need, and then use <strong>early stopping</strong> and other regularization techniques such as <strong>dropout</strong> to prevent our nets from overfitting.</p>
<p>Other hyperparameters includes the <strong>learning rate, batch size</strong> and so on. As for the <strong>learning rate</strong>, in general, the optimal learning rate is about half of the maximum learning rate. So we can start with a large learning rate that will make our training algorithm diverge, and then divide the value by 3 and try again, and repeat until the training algorithm stops diverging. The optimal <strong>batch size</strong> is usually lower than 32. We know larger batch size can lead to more precise estimate of the gradients, but since we normally will not use the vanilla gradient descent, the precision of gradients are not that important than for other machine learning algorithms. On the other hand, however, we know, having a larger batch means higher degree of parallelism and therefore, faster training. So normally the batch size will not exceed 32, but will also not be too small. Note that if you use batchNorm, the size should generally larger than 20. Further, we don’t really need to tweak the number of training iterations, because <strong>early stopping</strong> is preferred.</p>
<h2 id="Advanced-Topics"><a href="#Advanced-Topics" class="headerlink" title="Advanced Topics"></a>Advanced Topics</h2><h3 id="Activation-functions"><a href="#Activation-functions" class="headerlink" title="Activation functions"></a>Activation functions</h3><p><strong>Gradient vanishing</strong> is a long-existing problem when training deep neural nets. It refers to the phenomenon that the gradients get smaller and smaller as back propagation progresses down to the lower layers. When gradient vanishing happens, the weights of lower layers remains hardly changed because their gradients are neglectable.</p>
<p>In 2010, a paper written by Xavier Glorot and Yoshua Bengio(one of the Turing Award receiver in 2018) dived deep in this problem, and found a few suspects. One of these suspects is the sigmoid activation function and the normal distribution initialization scheme. They found that under this setting, the variance of the outputs is much greater than the inputs and will keeps increasing until the sigmoid function saturates, i.e. gets close to the value 0 or 1. When it saturates, the gradients are close to zero so there is virtually no gradient to propagate back through the network, then gradient vanishing happens.</p>
<p>Glorot and Bengio argue that to solve this problem, we need <strong>the variance of the outputs of  outputs of each layer to be equal to the variance of its input, we also need the gradients to have equal variance before and after flowing through a layer in the reverse direction</strong>. They further proposed a novel initialization method, called Xavier initialization or Glorot initialization. The pseudo-code is as below:</p>
<pre class=" language-pseudocode"><code class="language-pseudocode">for-each input-hidden weight
  variance = 2.0 / (fan-in +fan-out)
  stddev = sqrt(variance)
  weight = gaussian(mean=0.0, stddev)
end-for
</code></pre>


As you can see, it is just a normal distribution with mean 0 and variance $\sigma^2 = \dfrac{2}{\text{fan}_{in} + \text{fan}_{out}}$There is also a uniform distribution version: the range of this uniform distribution is from $-\sqrt{\dfrac{6}{(\text{fan}_{in} + \text{fan}_{out})}}$  to $\sqrt{\dfrac{6}{(\text{fan}_{in} + \text{fan}_{out})}}$.

Glorot initialization proves good for activation functions like linear(i.e. no activation), tanh, sigmoid and softmax. There are also some variants, whose difference is only the scale of the variance and whether they use $\text{fan}_{in}$ or $\text{fan}_{avg} = \dfrac{\text{fan}_{in} + \text{fan}_{out}}{2}$. For example, He initialization is suitable for ReLU and its variants like ELU, and its variance is $\dfrac{2}{\text{fan}_{in}}$. LeCun initialization differs from Glorot only in that it uses $\text{fan}_{in}$ instead of $\text{fan}_{avg}$, and it is for SELU.

All these methods have uniform version, you can get the range $r$ by the equation: $r =\sqrt{3\sigma^2}$. 


<p>Keras uses Glorot initialization with a uniform distribution by default.</p>
<p>Because of Glorot and Bengio, people started to realize that ReLU is a better activation function than sigmoid in deep learning, for the positive values will not saturate and it is quite fast to compute. But ReLU also has its own drawbacks.  The problem is called <em>dying ReLUs</em>: during training, some neurons stop output anything but 0, so they are effectively dead. To solve this, people came up with some variants of ReLU, for example, the leaky ReLU = $\max(\alpha z,z)$ and the randomized leaky ReLU(RReLU). The parametric leaky ReLU treats $\alpha$ as a learnable parameter. Experiments show it strongly outperforms ReLU on large image datasets but tends to overfit on smaller datasets.</p>
<p>In 2015, a new activation function called <em>exponential linear unit</em>(ELU) was proposed. It is reported to outperform all ReLU variants both in training time and the results of the test set. The only difference between ELU and leaky ReLU is that its negative part is $\alpha(\exp(z) - 1)$ instead of $\alpha z$. Notice that the exponential function makes it slower at test time. SELU is just a scaled version of ELU.</p>
<p>From practice, we say in general SELU &gt; ELU &gt; leaky ReLU (and its variants) &gt; ReLU &gt; tanh &gt; sigmoid.</p>
<h3 id="Optimizers"><a href="#Optimizers" class="headerlink" title="Optimizers"></a>Optimizers</h3><p>Since we are talking about <em>tricks</em> here, the algorithm details of each optimizer will not be emphasized. For more details, refer to the book I mentioned above, it has a wonderful introduction to these optimizers.</p>
<ul>
<li>Tl;dr, use Adam. But if you found your dataset may just be allergic to adaptive gradients, try plain NAG.</li>
<li>When using momentum, the momentum value of 0.9 usually works well.</li>
<li>Nesterov Accelerated Gradient(NAG) is a small variant of momentum, and <strong>is always faster than vanilla Momentum optimization</strong>.</li>
<li>Adagrad often stops too early when training neural networks.</li>
<li>RMSProp fixes the problem of Adagrad by accumulating only the gradients from the most recent iterations, the decay rate is typically set to 0.9 and it almost works well for all cases so you don’t have to tune it. Except on very simple problems, it almost always beats Adagrad.</li>
<li>Adam combines the idea of momentum and RMSProp.  The momentum decay hyperparameter is typically set to 0.9, while the scaling decay hyperparameter is often initialized to 0.999. <strong>Since Adam is an adaptive learning rate algorithm, it requires less tuning of the learning rate</strong>.</li>
</ul>
<h3 id="Batch-normalization"><a href="#Batch-normalization" class="headerlink" title="Batch normalization"></a>Batch normalization</h3><p>In a 2015 paper, Sergey Ioffe and Christian Szegedy proposed a technique called <em>Batch Normalization (BN)</em> to address the vanishing/exploding gradients problems.</p>
<p>The technique consists of adding an operation in the model just before or after the activation function of each hidden layer, simply zero-centering and normalizing each input, then scaling and shifting the result using two new parameter vectors per layer: one for scaling, the other for shifting. In other words, this operation <strong>lets the model<br>learn the optimal scale and mean of each of the layer’s inputs</strong>. </p>
<p>This method is thoroughly discussed all over the internet, and the steps are quite clear and simple, so I will not talk about the algorithm details here.  </p>
<p>The authors claimed that this technique considerably improved <strong>all the DNNs</strong> they experimented with. The vanishing gradients problem was strongly reduced and the networks become less sensitive to the weight initialization. They were able to use large learning rates to speed the training process.</p>
<h3 id="Gradient-clipping"><a href="#Gradient-clipping" class="headerlink" title="Gradient clipping"></a>Gradient clipping</h3><p>Though it achieved very good performance, BatchNorm is tricky to use in RNNs. One method to deal with <strong>gradient exploding</strong> is gradient clipping. </p>
<p>In Keras, implementing gradient clipping can be achieved by just setting the <code>clipvalue</code> or <code>clipnorm</code> argument when creating an optimizer:</p>
<pre class=" language-python"><code class="language-python">optimizer <span class="token operator">=</span> keras<span class="token punctuation">.</span>optimizer<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>clipvalue<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>compile<span class="token punctuation">(</span>lose<span class="token operator">=</span><span class="token string">"mse"</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span>optimzer<span class="token punctuation">)</span>
</code></pre>
<p>With the above code,  every component of the gradient vector will be clipped to a value between -1.0 and 1.0. In practice it works quite good, but you may argue that by doing this, the direction of the gradient vector will be changed drastically under this setting. For example, if the gradient vector is [0.9, 100], after clipping you will get [0.9, 1.0]. To avoid this, you may try the argument <code>clipnorm</code>, <strong>this will clip the whole gradient if its L2 norm is greater than the threshold</strong>. Like we said, simply performing clipping by value is good enough in most cases. In practice you may try both and see the results on the validation set to decide.</p>
<h2 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h2><p>The book actually covers much more than what I mentioned above, for example, reusing pretrained layers, dropout and MC dropout. You should visit chapter 10 and chapter 11 if you need more guidelines.</p>
<p>I will also actively add other topics into this article whenever I found some tricks useful.</p>

        
                <blockquote style="margin: 2em 0 0;padding: 0.5em 1em;border-left: 3px solid #F44336;background-color: #F5F5F5;list-style: none;">
                    <p><strong>
                         
                            This blog is under a <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/deed.zh" target="_blank">CC BY-NC-SA 3.0 Unported License</a>
                        </strong>
                        <br>
                        <strong>Link to this article: </strong><a href="https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/">https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/</a>
                    </p>
                </blockquote>
        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
    <!-- 使用 DISQUS -->
<div id="disqus-comment">
    <div id="disqus_thread"></div>
<script type="text/javascript">
    var disqus_config = function () {
        this.page.url = 'https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/';  // Replace PAGE_URL with your page's canonical URL variable
        this.page.identifier = 'https://huangweiran.club/2019/10/04/Tricks-of-training-neural-nets/'; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
    };
</script>
<script type="text/ls-javascript" id="disqus-thread-script">
    queue.offer(function() {
            (function() { // DON'T EDIT BELOW THIS LINE
                var d = document;
                var s = d.createElement('script');
                s.src = '//EtoDemerzel.disqus.com/embed.js';
                s.setAttribute('data-timestamp', + new Date());
                (d.head || d.body).appendChild(s);
            })();
        });
</script>

</div>
<style>
    #disqus-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2019/10/06/全部文章索引/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            Newer
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2019/06/07/Machine-Learning-Topics/" id="post_nav-older" class="next-content">
            Older
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(https://s1.ax1x.com/2018/09/03/PzuCZR.png);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="https://s1.ax1x.com/2018/09/03/PznIMQ.png" alt="Weiran Huang's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        huangweiran1998@outlook.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="huangweiran1998@outlook.com" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                Home
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    Archives
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2019/11/">November 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/10/">October 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/06/">June 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/12/">December 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/11/">November 2018<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/09/">September 2018<span class="sidebar_archives-count">5</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/08/">August 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">May 2018<span class="sidebar_archives-count">2</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                Categories
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                <a class="sidebar_archives-link" href="/categories/Literature/">Literature<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/ML/">ML<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/categories/NLP/">NLP<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/Python/">Python<span class="sidebar_archives-count">4</span></a></li><li><a class="sidebar_archives-link" href="/categories/all/">all<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/categories/math/">math<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/categories/tech/">tech<span class="sidebar_archives-count">5</span></a>
            </ul>
        </li>
        
    

    <!-- Pages  -->
    
        <li>
            <a href="/about" title="About">
                
                    <i class="material-icons sidebar-material-icons">person</i>
                
                About
            </a>
        </li>
        
    
        <li>
            <a href="/wiki" title="Wiki">
                
                    <i class="material-icons sidebar-material-icons">book</i>
                
                Wiki
            </a>
        </li>
        
    
        <li>
            <a href="https://huangweiran.club/online-cv/" title="Online CV">
                
                    <i class="material-icons sidebar-material-icons">portrait</i>
                
                Online CV
            </a>
        </li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                Number of articles
                <span class="sidebar-badge">18</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->

    <div class="sidebar-divider"></div>


<!-- Theme Material -->

    <a href="https://github.com/viosey/hexo-theme-material"  class="sidebar-footer-text-a" target="_blank">
        <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
            Theme - Material
            <span class="sidebar-badge badge-circle">i</span>
        </div>
    </a>


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    
        <a href="https://twitter.com/twitter" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-twitter">
                <span class="visuallyhidden">Twitter</span>
            </button><!--
     --></a>
    

    <!-- Facebook -->
    
        <a href="https://www.facebook.com/profile.php?id=100006603762815" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook">
                <span class="visuallyhidden">Facebook</span>
            </button><!--
     --></a>
    

    <!-- Google + -->
    

    <!-- Weibo -->
    

    <!-- Instagram -->
    
        <a href="https://www.instagram.com/etodemerzel0427/" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram">
                <span class="visuallyhidden">Instagram</span>
            </button><!--
     --></a>
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/EtoDemerzel0427" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    
        <a href="https://www.linkedin.com/in/weiranhuang/" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-linkedin">
                <span class="visuallyhidden">LinkedIn</span>
            </button><!--
     --></a>
    

    <!-- Zhihu -->
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    

    <!-- V2EX -->
    

    <!-- Segmentfault -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;<span year></span>&nbsp;My Trantor
            
                <br>
                
                    Act Justly, Love Mercy, Walk Humbly.
                
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?Bn9UzEm8RrBSxqyZB0zPjA==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>









   <!-- 使用 DISQUS js 代码 -->
<script id="dsq-count-scr" src="//EtoDemerzel.disqus.com/count.js" async></script>





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
    
</script>

<!-- MathJax Load-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

    <script src="https://cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>




<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    var copyrightNow = new Date().getFullYear();
    var textContent = document.querySelector('span[year]')

    copyrightSince = 2018;
    if (copyrightSince === copyrightNow||copyrightSince === 0000) {
        textContent.textContent = copyrightNow
    } else {
        textContent.textContent = copyrightSince + ' - ' + copyrightNow
    }

    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.6 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>
